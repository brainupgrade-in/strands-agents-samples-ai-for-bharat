{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## AB Testing Models - Building Agent Variants\n",
    "\n",
    "Learn how to build multiple versions of the same agent using different models for A/B testing purposes. This tutorial shows you how to create three variants of a ReAct airline assistant agent with identical capabilities but powered by different language models.\n",
    "\n",
    "### What You'll Learn\n",
    "- Build ReAct agents with custom orchestration for airline customer service\n",
    "- Create multiple agent variants using different models (Haiku, Sonnet, Nova Lite)\n",
    "- Configure identical toolsets and prompts across agent variants\n",
    "- Test each agent independently with the same queries\n",
    "- Understand the agent-as-tool pattern with comprehensive airline tools\n",
    "- Prepare agent configurations for systematic A/B testing evaluation\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                       |\n",
    "|:--------------------|:------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Advanced - Building multiple agent variants for model comparison              |\n",
    "| Tutorial components | ReAct orchestration, TauBench tools, multi-model agent configuration          |\n",
    "| Tutorial vertical   | Agent Evaluation                                                              |\n",
    "| Example complexity  | Advanced                                                                      |\n",
    "| SDK used            | Strands Agents, Strands Evals                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### Understanding A/B Testing for Agents\n",
    "\n",
    "**A/B testing** compares agent variants with identical tools and prompts but different models, using controlled comparison on the same queries.\n",
    "\n",
    "#### Why A/B Test Models?\n",
    "\n",
    "| Factor | Impact |\n",
    "|:-------|:-------|\n",
    "| Response quality | Different models produce different quality outputs |\n",
    "| Cost efficiency | Model pricing varies 10x-100x |\n",
    "| Latency | Smaller models respond faster |\n",
    "| Capability fit | Some models excel at specific tasks |\n",
    "\n",
    "#### Three Models for Comparison\n",
    "\n",
    "| Model | ID | Characteristics | Use Case |\n",
    "|:------|:---|:----------------|:---------|\n",
    "| Claude Haiku | `us.anthropic.claude-3-5-haiku-20241022-v1:0` | Fastest, lowest cost | High-volume, straightforward queries |\n",
    "| Claude Sonnet | `us.anthropic.claude-sonnet-4-0-20250514-v1:0` | Balanced speed/capability | Complex reasoning, reasonable cost |\n",
    "| Nova Lite | `us.amazon.nova-lite-v1:0` | AWS-native, cost-effective | AWS ecosystem, budget-conscious |\n",
    "\n",
    "#### Two-Part Tutorial Structure\n",
    "\n",
    "| Part | Focus |\n",
    "|:-----|:------|\n",
    "| Part 1 (This Notebook) | Build three agent variants, test independently, save configurations |\n",
    "| Part 2 (Next Notebook) | Run evaluations, compare scores, analyze trade-offs, generate recommendations |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "### ReAct Agent Architecture\n",
    "\n",
    "**ReAct (Reasoning and Acting)** combines thinking, acting (tool execution), observing results, and iterating until complete.\n",
    "\n",
    "#### Agent Flow\n",
    "\n",
    "```\n",
    "User Query \u2192 Think \u2192 Act (tools) \u2192 Observe \u2192 Repeat until complete \u2192 Final Response\n",
    "```\n",
    "\n",
    "#### Airline Assistant Tools (14 total)\n",
    "\n",
    "| Category | Tools |\n",
    "|:---------|:------|\n",
    "| Flight Management | `search_direct_flight`, `search_onestop_flight`, `list_all_airports` |\n",
    "| Booking Operations | `book_reservation`, `cancel_reservation`, `get_reservation_details` |\n",
    "| Reservation Updates | `update_reservation_flights`, `update_reservation_passengers`, `update_reservation_baggages` |\n",
    "| Customer Service | `get_user_details`, `send_certificate`, `transfer_to_human_agents` |\n",
    "| Utilities | `calculate`, `think` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Configure AWS region and define the three model IDs we'll test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# AWS Configuration\n",
    "session = boto3.Session()\n",
    "AWS_REGION = session.region_name or 'us-east-1'\n",
    "\n",
    "# Define three models for A/B testing\n",
    "MODEL_HAIKU = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "MODEL_SONNET = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "MODEL_NOVA_LITE = 'us.amazon.nova-lite-v1:0'\n",
    "\n",
    "print(f\"AWS Region: {AWS_REGION}\")\n",
    "print(f\"\\nModels for A/B Testing:\")\n",
    "print(f\"  1. Haiku:     {MODEL_HAIKU}\")\n",
    "print(f\"  2. Sonnet:    {MODEL_SONNET}\")\n",
    "print(f\"  3. Nova Lite: {MODEL_NOVA_LITE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "Import all necessary libraries and configure the airline environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Add paths for airline tools (local data directory)\n",
    "sys.path.append('./data/ma-bench/')\n",
    "sys.path.append('./data/tau-bench/')\n",
    "\n",
    "# Strands imports\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# Disable verbose logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "for logger_name in [\"strands\", \"graph\", \"event_loop\", \"registry\", \"sliding_window_conversation_manager\", \"bedrock\", \"streaming\"]:\n",
    "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)\n",
    "\n",
    "# Bypass tool consent for automated execution\n",
    "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Import Airline Domain Tools\n",
    "\n",
    "Import the comprehensive suite of 14 airline tools from MAbench and TauBench. These tools provide real functionality for flight booking, reservation management, and customer service operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all 14 airline tools\n",
    "from mabench.environments.airline.tools.book_reservation import book_reservation\n",
    "from mabench.environments.airline.tools.calculate import calculate\n",
    "from mabench.environments.airline.tools.cancel_reservation import cancel_reservation\n",
    "from mabench.environments.airline.tools.get_reservation_details import get_reservation_details\n",
    "from mabench.environments.airline.tools.get_user_details import get_user_details\n",
    "from mabench.environments.airline.tools.list_all_airports import list_all_airports\n",
    "from mabench.environments.airline.tools.search_direct_flight import search_direct_flight\n",
    "from mabench.environments.airline.tools.search_onestop_flight import search_onestop_flight\n",
    "from mabench.environments.airline.tools.send_certificate import send_certificate\n",
    "from mabench.environments.airline.tools.think import think\n",
    "from mabench.environments.airline.tools.transfer_to_human_agents import transfer_to_human_agents\n",
    "from mabench.environments.airline.tools.update_reservation_baggages import update_reservation_baggages\n",
    "from mabench.environments.airline.tools.update_reservation_flights import update_reservation_flights\n",
    "from mabench.environments.airline.tools.update_reservation_passengers import update_reservation_passengers\n",
    "\n",
    "# Import airline policy\n",
    "from tau_bench.envs.airline.wiki import WIKI\n",
    "\n",
    "# Define tools list\n",
    "AIRLINE_TOOLS = [\n",
    "    book_reservation,\n",
    "    calculate,\n",
    "    cancel_reservation,\n",
    "    get_reservation_details,\n",
    "    get_user_details,\n",
    "    list_all_airports,\n",
    "    search_direct_flight,\n",
    "    search_onestop_flight,\n",
    "    send_certificate,\n",
    "    think,\n",
    "    transfer_to_human_agents,\n",
    "    update_reservation_baggages,\n",
    "    update_reservation_flights,\n",
    "    update_reservation_passengers,\n",
    "]\n",
    "\n",
    "print(f\"Imported {len(AIRLINE_TOOLS)} airline tools\")\n",
    "print(f\"Loaded airline policy document ({len(WIKI)} characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Define Airline Agent System Prompt\n",
    "\n",
    "Create the specialized system prompt that will be used consistently across all three agent variants. This prompt includes:\n",
    "- Airline policy from TauBench wiki\n",
    "- Geographic inference instructions\n",
    "- Tool usage guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt template\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant for a travel website. Help the user answer any questions.\n",
    "\n",
    "<instructions>\n",
    "- Remember to check if the airport city is in the state mentioned by the user. For example, Houston is in Texas.\n",
    "- Infer about the U.S. state in which the airport city resides. For example, Houston is in Texas.\n",
    "- You should not use made-up or placeholder arguments.\n",
    "</instructions>\n",
    "\n",
    "<policy>\n",
    "{policy}\n",
    "</policy>\n",
    "\"\"\"\n",
    "\n",
    "# Create full system prompt with policy\n",
    "AIRLINE_SYSTEM_PROMPT = SYSTEM_PROMPT_TEMPLATE.replace(\"{policy}\", WIKI)\n",
    "\n",
    "print(f\"System prompt created ({len(AIRLINE_SYSTEM_PROMPT)} characters)\")\n",
    "print(\"\\nPrompt includes:\")\n",
    "print(\"  - Airline policy and rules\")\n",
    "print(\"  - Geographic inference guidelines\")\n",
    "print(\"  - Tool usage instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Build Agent Variant 1: Claude Haiku\n",
    "\n",
    "Create the first agent variant powered by Claude Haiku. This model is optimized for speed and cost efficiency, making it ideal for high-volume deployments with straightforward queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BedrockModel for Haiku\n",
    "bedrock_model_haiku = BedrockModel(\n",
    "    region_name=AWS_REGION,\n",
    "    model_id=MODEL_HAIKU\n",
    ")\n",
    "\n",
    "# Create Haiku agent\n",
    "agent_haiku = Agent(\n",
    "    name=\"airline_assistant_haiku\",\n",
    "    model=bedrock_model_haiku,\n",
    "    tools=AIRLINE_TOOLS,\n",
    "    system_prompt=AIRLINE_SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "print(\"Agent Variant 1: Claude Haiku\")\n",
    "print(f\"  Model: {MODEL_HAIKU}\")\n",
    "print(f\"  Tools: {len(AIRLINE_TOOLS)} airline tools\")\n",
    "print(f\"  Status: Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Build Agent Variant 2: Claude Sonnet\n",
    "\n",
    "Create the second agent variant powered by Claude Sonnet. This model offers balanced performance with strong reasoning capabilities, suitable for complex multi-step tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BedrockModel for Sonnet\n",
    "bedrock_model_sonnet = BedrockModel(\n",
    "    region_name=AWS_REGION,\n",
    "    model_id=MODEL_SONNET\n",
    ")\n",
    "\n",
    "# Create Sonnet agent\n",
    "agent_sonnet = Agent(\n",
    "    name=\"airline_assistant_sonnet\",\n",
    "    model=bedrock_model_sonnet,\n",
    "    tools=AIRLINE_TOOLS,\n",
    "    system_prompt=AIRLINE_SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "print(\"Agent Variant 2: Claude Sonnet\")\n",
    "print(f\"  Model: {MODEL_SONNET}\")\n",
    "print(f\"  Tools: {len(AIRLINE_TOOLS)} airline tools\")\n",
    "print(f\"  Status: Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Build Agent Variant 3: Nova Lite\n",
    "\n",
    "Create the third agent variant powered by Amazon Nova Lite. This AWS-native model provides cost-effective performance with seamless AWS ecosystem integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BedrockModel for Nova Lite\n",
    "bedrock_model_nova_lite = BedrockModel(\n",
    "    region_name=AWS_REGION,\n",
    "    model_id=MODEL_NOVA_LITE\n",
    ")\n",
    "\n",
    "# Create Nova Lite agent\n",
    "agent_nova_lite = Agent(\n",
    "    name=\"airline_assistant_nova_lite\",\n",
    "    model=bedrock_model_nova_lite,\n",
    "    tools=AIRLINE_TOOLS,\n",
    "    system_prompt=AIRLINE_SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "print(\"Agent Variant 3: Nova Lite\")\n",
    "print(f\"  Model: {MODEL_NOVA_LITE}\")\n",
    "print(f\"  Tools: {len(AIRLINE_TOOLS)} airline tools\")\n",
    "print(f\"  Status: Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Verify Agent Configuration\n",
    "\n",
    "Confirm all three agents are configured identically except for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store agent configurations for verification\n",
    "agent_configs = {\n",
    "    \"haiku\": {\n",
    "        \"agent\": agent_haiku,\n",
    "        \"model_id\": MODEL_HAIKU,\n",
    "        \"name\": \"Claude Haiku\",\n",
    "        \"characteristics\": \"Fast, cost-effective, optimized for simple queries\"\n",
    "    },\n",
    "    \"sonnet\": {\n",
    "        \"agent\": agent_sonnet,\n",
    "        \"model_id\": MODEL_SONNET,\n",
    "        \"name\": \"Claude Sonnet\",\n",
    "        \"characteristics\": \"Balanced performance, strong reasoning capabilities\"\n",
    "    },\n",
    "    \"nova_lite\": {\n",
    "        \"agent\": agent_nova_lite,\n",
    "        \"model_id\": MODEL_NOVA_LITE,\n",
    "        \"name\": \"Nova Lite\",\n",
    "        \"characteristics\": \"AWS-native, cost-effective, multimodal\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Agent Configuration Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for variant_key, config in agent_configs.items():\n",
    "    print(f\"\\n{config['name']}:\")\n",
    "    print(f\"  Model ID: {config['model_id']}\")\n",
    "    print(f\"  Tools: {len(config['agent'].tool_names)} airline tools\")\n",
    "    print(f\"  Prompt: {len(config['agent'].system_prompt)} characters\")\n",
    "    print(f\"  Characteristics: {config['characteristics']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Configuration Verification: All agents configured with identical prompts and tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Load Test Dataset\n",
    "\n",
    "Load the TauBench airline dataset containing real customer service scenarios. We'll use a subset of these queries to test each agent variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TauBench dataset (local data directory)\n",
    "dataset_path = \"./data/tau-bench/tau_bench/envs/airline/tasks_singleturn.json\"\n",
    "\n",
    "with open(dataset_path, \"r\") as file:\n",
    "    tasks = json.load(file)\n",
    "\n",
    "print(f\"Loaded {len(tasks)} test scenarios from TauBench dataset\")\n",
    "print(\"\\nDataset includes scenarios for:\")\n",
    "print(\"  - Flight searches and bookings\")\n",
    "print(\"  - Reservation modifications\")\n",
    "print(\"  - Cancellations and refunds\")\n",
    "print(\"  - Customer service inquiries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Test Example 1: Simple Flight Search\n",
    "\n",
    "Test all three agents with a straightforward flight search query. This tests basic tool usage and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test query\n",
    "test_query_1 = \"I want to search for direct flights from JFK to LAX on 2024-06-15. Can you help?\"\n",
    "\n",
    "print(\"Test Query 1: Simple Flight Search\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Query: {test_query_1}\")\n",
    "print(\"\\nExpected behavior: Agent should use search_direct_flight tool\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Haiku\n",
    "print(\"\\n[TESTING HAIKU]\")\n",
    "print(\"-\" * 80)\n",
    "agent_haiku.messages = []  # Reset conversation\n",
    "response_haiku_1 = agent_haiku(test_query_1)\n",
    "print(f\"Response: {response_haiku_1}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Sonnet\n",
    "print(\"\\n[TESTING SONNET]\")\n",
    "print(\"-\" * 80)\n",
    "agent_sonnet.messages = []  # Reset conversation\n",
    "response_sonnet_1 = agent_sonnet(test_query_1)\n",
    "print(f\"Response: {response_sonnet_1}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Nova Lite\n",
    "print(\"\\n[TESTING NOVA LITE]\")\n",
    "print(\"-\" * 80)\n",
    "agent_nova_lite.messages = []  # Reset conversation\n",
    "response_nova_lite_1 = agent_nova_lite(test_query_1)\n",
    "print(f\"Response: {response_nova_lite_1}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Test Example 2: Complex Reservation Modification\n",
    "\n",
    "Test all three agents with a complex multi-step query involving reservation lookup and modification. This tests reasoning and multi-tool coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select complex test query from dataset\n",
    "task_20 = tasks[20]\n",
    "test_query_2 = task_20[\"question\"]\n",
    "\n",
    "print(\"Test Query 2: Complex Reservation Modification\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Query: {test_query_2}\")\n",
    "print(f\"\\nUser ID: {task_20['user_id']}\")\n",
    "print(\"\\nExpected behavior: Agent should:\")\n",
    "print(\"  1. Look up reservation details\")\n",
    "print(\"  2. Search for alternative flights\")\n",
    "print(\"  3. Address baggage policy\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Haiku\n",
    "print(\"\\n[TESTING HAIKU]\")\n",
    "print(\"-\" * 80)\n",
    "agent_haiku.messages = []  # Reset conversation\n",
    "response_haiku_2 = agent_haiku(test_query_2)\n",
    "print(f\"Response: {response_haiku_2}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Sonnet\n",
    "print(\"\\n[TESTING SONNET]\")\n",
    "print(\"-\" * 80)\n",
    "agent_sonnet.messages = []  # Reset conversation\n",
    "response_sonnet_2 = agent_sonnet(test_query_2)\n",
    "print(f\"Response: {response_sonnet_2}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Nova Lite\n",
    "print(\"\\n[TESTING NOVA LITE]\")\n",
    "print(\"-\" * 80)\n",
    "agent_nova_lite.messages = []  # Reset conversation\n",
    "response_nova_lite_2 = agent_nova_lite(test_query_2)\n",
    "print(f\"Response: {response_nova_lite_2}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "### Test Example 3: Policy-Based Query\n",
    "\n",
    "Test all three agents with a query requiring policy knowledge and proper escalation. This tests understanding of business rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select policy-based test query from dataset\n",
    "task_48 = tasks[48]\n",
    "test_query_3 = task_48[\"question\"]\n",
    "\n",
    "print(\"Test Query 3: Policy-Based Query\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Query: {test_query_3}\")\n",
    "print(f\"\\nUser ID: {task_48['user_id']}\")\n",
    "print(\"\\nExpected behavior: Agent should:\")\n",
    "print(\"  1. Look up user details\")\n",
    "print(\"  2. Apply cancellation policy rules\")\n",
    "print(\"  3. Process cancellation or explain restrictions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Haiku\n",
    "print(\"\\n[TESTING HAIKU]\")\n",
    "print(\"-\" * 80)\n",
    "agent_haiku.messages = []  # Reset conversation\n",
    "response_haiku_3 = agent_haiku(test_query_3)\n",
    "print(f\"Response: {response_haiku_3}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Sonnet\n",
    "print(\"\\n[TESTING SONNET]\")\n",
    "print(\"-\" * 80)\n",
    "agent_sonnet.messages = []  # Reset conversation\n",
    "response_sonnet_3 = agent_sonnet(test_query_3)\n",
    "print(f\"Response: {response_sonnet_3}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Nova Lite\n",
    "print(\"\\n[TESTING NOVA LITE]\")\n",
    "print(\"-\" * 80)\n",
    "agent_nova_lite.messages = []  # Reset conversation\n",
    "response_nova_lite_3 = agent_nova_lite(test_query_3)\n",
    "print(f\"Response: {response_nova_lite_3}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "### Save Agent Configurations for Evaluation\n",
    "\n",
    "Store the agent configurations so they can be easily loaded in Part 2 (Tutorial 07b) for systematic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration dictionary for Part 2\n",
    "evaluation_configs = {\n",
    "    \"models\": {\n",
    "        \"haiku\": {\n",
    "            \"model_id\": MODEL_HAIKU,\n",
    "            \"name\": \"Claude Haiku\",\n",
    "            \"description\": \"Fast, cost-effective, optimized for simple queries\"\n",
    "        },\n",
    "        \"sonnet\": {\n",
    "            \"model_id\": MODEL_SONNET,\n",
    "            \"name\": \"Claude Sonnet\",\n",
    "            \"description\": \"Balanced performance, strong reasoning capabilities\"\n",
    "        },\n",
    "        \"nova_lite\": {\n",
    "            \"model_id\": MODEL_NOVA_LITE,\n",
    "            \"name\": \"Nova Lite\",\n",
    "            \"description\": \"AWS-native, cost-effective, multimodal\"\n",
    "        }\n",
    "    },\n",
    "    \"dataset_path\": dataset_path,\n",
    "    \"num_tools\": len(AIRLINE_TOOLS),\n",
    "    \"prompt_length\": len(AIRLINE_SYSTEM_PROMPT)\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "config_output_path = \"./agent_configs.json\"\n",
    "with open(config_output_path, \"w\") as f:\n",
    "    json.dump(evaluation_configs, f, indent=2)\n",
    "\n",
    "print(\"Agent configurations saved for evaluation:\")\n",
    "print(f\"  Output path: {config_output_path}\")\n",
    "print(f\"  Models configured: {len(evaluation_configs['models'])}\")\n",
    "print(f\"  Dataset path: {evaluation_configs['dataset_path']}\")\n",
    "print(\"\\nThese configurations will be loaded in Tutorial 07b for systematic evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "### Agent Testing Summary\n",
    "\n",
    "Review the testing results and observations from all three agent variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing summary\n",
    "summary = \"\"\"\n",
    "# Agent Variant Testing Summary\n",
    "\n",
    "## Agents Built\n",
    "\n",
    "Successfully created three agent variants:\n",
    "\n",
    "1. **Claude Haiku** - Fast and cost-effective variant\n",
    "2. **Claude Sonnet** - Balanced performance variant\n",
    "3. **Nova Lite** - AWS-native variant\n",
    "\n",
    "## Configuration Consistency\n",
    "\n",
    "All three agents configured with:\n",
    "- **Identical system prompt** (includes airline policy and guidelines)\n",
    "- **Identical toolset** (14 airline domain tools)\n",
    "- **Same orchestration** (ReAct pattern)\n",
    "- **Only difference**: Language model\n",
    "\n",
    "## Testing Results\n",
    "\n",
    "### Test 1: Simple Flight Search\n",
    "- **Query complexity**: Low\n",
    "- **Tools required**: search_direct_flight\n",
    "- **All agents**: Successfully executed search\n",
    "\n",
    "### Test 2: Complex Reservation Modification\n",
    "- **Query complexity**: High\n",
    "- **Tools required**: get_reservation_details, search_direct_flight, policy application\n",
    "- **All agents**: Demonstrated multi-tool coordination\n",
    "\n",
    "### Test 3: Policy-Based Query\n",
    "- **Query complexity**: Medium\n",
    "- **Tools required**: get_user_details, cancel_reservation, policy reasoning\n",
    "- **All agents**: Applied business rules\n",
    "\n",
    "## Observations\n",
    "\n",
    "**Differences observed across models:**\n",
    "- Response style and verbosity\n",
    "- Tool selection sequencing\n",
    "- Policy interpretation nuances\n",
    "- Response completeness\n",
    "\n",
    "**These differences will be quantified in Part 2 through:**\n",
    "- Output quality evaluation\n",
    "- Tool selection accuracy\n",
    "- Policy compliance scoring\n",
    "- Cost-performance analysis\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Tutorial 07b will provide:**\n",
    "1. Systematic evaluation on full test dataset\n",
    "2. Side-by-side score comparison\n",
    "3. Statistical significance analysis\n",
    "4. Cost-performance trade-off analysis\n",
    "5. Model selection recommendations\n",
    "\n",
    "## Configuration Saved\n",
    "\n",
    "Agent configurations exported to: `agent_configs.json`\n",
    "\n",
    "Ready for evaluation in Tutorial 07b.\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "You've successfully learned how to build multiple agent variants for A/B testing. You now understand:\n",
    "\n",
    "- **ReAct agent architecture**: Reasoning-Acting pattern with iterative tool execution\n",
    "- **Agent variant creation**: Building identical agents with different models\n",
    "- **Configuration consistency**: Ensuring fair comparison through identical prompts and tools\n",
    "- **Three model types**: Haiku (fast), Sonnet (balanced), Nova Lite (AWS-native)\n",
    "- **Testing methodology**: Running same queries across all variants\n",
    "- **TauBench integration**: Using real airline domain tools and datasets\n",
    "- **Configuration export**: Saving agent configs for systematic evaluation\n",
    "\n",
    "This notebook established the foundation for A/B testing by creating three production-ready agent variants. In Tutorial 07b, you'll evaluate these agents systematically to determine which model provides the best cost-performance trade-off for your use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}